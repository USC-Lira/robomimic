
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_pos', 'object', 'robot0_gripper_qpos', 'robot0_eef_quat']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []

============= Loaded Environment Metadata =============
obs key object with shape (23,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name Lifteither
Action size is 7
Lifteither
{
    "camera_depths": false,
    "controller_configs": {
        "control_delta": true,
        "damping_ratio": 1,
        "damping_ratio_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 700,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": "Panda",
    "use_camera_obs": false,
    "use_object_obs": true
}

wandb: Currently logged in as: thegrey (p-gaze-for-robots). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.2
wandb: Run data is saved locally in /home/dhanush/shreya_gaze_project/robomimic/robomimic/../hbc_trained_models_54_data_25_horizon_kl_5e-4_new_params/subgoal_horizon_25_kl_5e-4_new_params/20240701010137/logs/wandb/run-20240701_010142-3ha10v1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run subgoal_horizon_25_kl_5e-4_new_params
wandb:  View project at https://wandb.ai/p-gaze-for-robots/gaze_for_robots
wandb:  View run at https://wandb.ai/p-gaze-for-robots/gaze_for_robots/runs/3ha10v1n
ObservationKeyToModalityDict: latent not found, adding latent to mapping with assumed low_dim modality!

============= Model Summary =============
ObservationKeyToModalityDict: mean not found, adding mean to mapping with assumed low_dim modality!
ObservationKeyToModalityDict: logvar not found, adding logvar to mapping with assumed low_dim modality!
ObservationKeyToModalityDict: action not found, adding action to mapping with assumed low_dim modality!
HBC(subgoal_horizon=25, actor_horizon=10, subgoal_update_interval=25, mode=separate, actor_use_random_subgoals=False)
Planner:
  GL_VAE (
    ModuleDict(
      (goal_network): VAE(
        (nets): ModuleDict(
          (encoder): MIMO_MLP(
              encoder=ObservationGroupEncoder(
                  group=input
                  ObservationEncoder(
                      Key(
                          name=object
                          shape=[23]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_eef_pos
                          shape=[3]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_eef_quat
                          shape=[4]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_gripper_qpos
                          shape=[2]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      output_shape=[32]
                  )
                  group=condition
                  ObservationEncoder(
                      Key(
                          name=object
                          shape=[23]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_eef_pos
                          shape=[3]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_eef_quat
                          shape=[4]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_gripper_qpos
                          shape=[2]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      output_shape=[32]
                  )
              )
      
              mlp=MLP(
                  input_dim=64
                  output_dim=400
                  layer_dims=[300]
                  layer_func=Linear
                  dropout=None
                  act=ReLU
                  output_act=ReLU
              )
      
              decoder=ObservationDecoder(
                  Key(
                      name=mean
                      shape=(16,)
                      modality=low_dim
                      net=(Linear(in_features=400, out_features=16, bias=True))
                  )
                  Key(
                      name=logvar
                      shape=(16,)
                      modality=low_dim
                      net=(Linear(in_features=400, out_features=16, bias=True))
                  )
              )
          )
          (decoder): MIMO_MLP(
              encoder=ObservationGroupEncoder(
                  group=input
                  ObservationEncoder(
                      Key(
                          name=latent
                          shape=(16,)
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      output_shape=[16]
                  )
                  group=condition
                  ObservationEncoder(
                      Key(
                          name=object
                          shape=[23]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_eef_pos
                          shape=[3]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_eef_quat
                          shape=[4]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      Key(
                          name=robot0_gripper_qpos
                          shape=[2]
                          modality=low_dim
                          randomizer=None
                          net=None
                          sharing_from=None
                      )
                      output_shape=[32]
                  )
              )
      
              mlp=MLP(
                  input_dim=48
                  output_dim=400
                  layer_dims=[300]
                  layer_func=Linear
                  dropout=None
                  act=ReLU
                  output_act=ReLU
              )
      
              decoder=ObservationDecoder(
                  Key(
                      name=object
                      shape=[23]
                      modality=low_dim
                      net=(Linear(in_features=400, out_features=23, bias=True))
                  )
                  Key(
                      name=robot0_eef_pos
                      shape=[3]
                      modality=low_dim
                      net=(Linear(in_features=400, out_features=3, bias=True))
                  )
                  Key(
                      name=robot0_eef_quat
                      shape=[4]
                      modality=low_dim
                      net=(Linear(in_features=400, out_features=4, bias=True))
                  )
                  Key(
                      name=robot0_gripper_qpos
                      shape=[2]
                      modality=low_dim
                      net=(Linear(in_features=400, out_features=2, bias=True))
                  )
              )
          )
          (prior): GaussianPrior(
              latent_dim=16
              latent_clip=None
              learnable=False
              input_dependent=False
              use_gmm=False
          )
        )
      )
    )
  )

Policy:
  BC_RNN (
    ModuleDict(
      (policy): RNNActorNetwork(
          action_dim=7
  
          encoder=ObservationGroupEncoder(
              group=obs
              ObservationEncoder(
                  Key(
                      name=object
                      shape=[23]
                      modality=low_dim
                      randomizer=None
                      net=None
                      sharing_from=None
                  )
                  Key(
                      name=robot0_eef_pos
                      shape=[3]
                      modality=low_dim
                      randomizer=None
                      net=None
                      sharing_from=None
                  )
                  Key(
                      name=robot0_eef_quat
                      shape=[4]
                      modality=low_dim
                      randomizer=None
                      net=None
                      sharing_from=None
                  )
                  Key(
                      name=robot0_gripper_qpos
                      shape=[2]
                      modality=low_dim
                      randomizer=None
                      net=None
                      sharing_from=None
                  )
                  output_shape=[32]
              )
          )
  
          rnn=RNN_Base(
            (per_step_net): Sequential(
              (0): MLP(
                  input_dim=400
                  output_dim=1024
                  layer_dims=[1024]
                  layer_func=Linear
                  dropout=None
                  act=ReLU
                  output_act=ReLU
              )
              (1): ObservationDecoder(
                  Key(
                      name=action
                      shape=(7,)
                      modality=low_dim
                      net=(Linear(in_features=1024, out_features=7, bias=True))
                  )
              )
            )
            (nets): LSTM(32, 400, num_layers=2, batch_first=True)
          )
      )
    )
  )

SequenceDataset: loading dataset into memory...
  0%|          | 0/54 [00:00<?, ?it/s]100%|##########| 54/54 [00:00<00:00, 1402.25it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/14977 [00:00<?, ?it/s] 18%|#8        | 2769/14977 [00:00<00:00, 27683.89it/s] 37%|###7      | 5608/14977 [00:00<00:00, 28094.77it/s] 56%|#####6    | 8453/14977 [00:00<00:00, 28256.05it/s] 75%|#######5  | 11279/14977 [00:00<00:00, 28213.86it/s] 94%|#########4| 14101/14977 [00:00<00:00, 22393.66it/s]100%|##########| 14977/14977 [00:00<00:00, 24791.22it/s]

============= Training Dataset =============
SequenceDataset (
	path=/home/dhanush/shreya_gaze_project/robosuite_vd/robosuite/models/assets/demonstrations/wo_gaze_54_demos/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=none
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=54
	num_sequences=14977
)

**************************************************
Warnings generated by robomimic have been duplicated here (from above) for convenience. Please check them carefully.
**************************************************

  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
run failed with error:
index 24 is out of bounds for dimension 1 with size 10

Traceback (most recent call last):
  File "robomimic/scripts/train.py", line 382, in main
    train(config, device=device)
  File "robomimic/scripts/train.py", line 197, in train
    step_log = TrainUtils.run_epoch(
  File "/home/dhanush/shreya_gaze_project/robomimic/robomimic/utils/train_utils.py", line 555, in run_epoch
    input_batch = model.process_batch_for_training(batch)
  File "/home/dhanush/shreya_gaze_project/robomimic/robomimic/algo/hbc.py", line 148, in process_batch_for_training
    input_batch["planner"] = self.planner.process_batch_for_training(batch)
  File "/home/dhanush/shreya_gaze_project/robomimic/robomimic/algo/gl.py", line 117, in process_batch_for_training
    input_batch["subgoals"] = {k: batch["next_obs"][k][:, self._subgoal_horizon - 1, :] for k in batch["next_obs"]}
  File "/home/dhanush/shreya_gaze_project/robomimic/robomimic/algo/gl.py", line 117, in <dictcomp>
    input_batch["subgoals"] = {k: batch["next_obs"][k][:, self._subgoal_horizon - 1, :] for k in batch["next_obs"]}
IndexError: index 24 is out of bounds for dimension 1 with size 10

Exception ignored in: <function MjRenderContext.__del__ at 0x7f30104475e0>
Traceback (most recent call last):
  File "/home/dhanush/robosuite_vd/robosuite/utils/binding_utils.py", line 199, in __del__
    self.gl_ctx.free()
  File "/home/dhanush/robosuite_vd/robosuite/renderers/context/egl_context.py", line 149, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE, EGL.EGL_NO_SURFACE, EGL.EGL_NO_CONTEXT)
  File "/home/dhanush/miniconda3/envs/robosuite_vd/lib/python3.8/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x7f300ed75e40>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7f301050d240>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7f301050d240>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7f3010762c40>,
	),
	result = 0
)
Exception ignored in: <function EGLGLContext.__del__ at 0x7f3010447430>
Traceback (most recent call last):
  File "/home/dhanush/robosuite_vd/robosuite/renderers/context/egl_context.py", line 155, in __del__
    self.free()
  File "/home/dhanush/robosuite_vd/robosuite/renderers/context/egl_context.py", line 149, in free
    EGL.eglMakeCurrent(EGL_DISPLAY, EGL.EGL_NO_SURFACE, EGL.EGL_NO_SURFACE, EGL.EGL_NO_CONTEXT)
  File "/home/dhanush/miniconda3/envs/robosuite_vd/lib/python3.8/site-packages/OpenGL/error.py", line 230, in glCheckError
    raise self._errorClass(
OpenGL.raw.EGL._errors.EGLError: EGLError(
	err = EGL_NOT_INITIALIZED,
	baseOperation = eglMakeCurrent,
	cArguments = (
		<OpenGL._opaque.EGLDisplay_pointer object at 0x7f300ed75e40>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7f301050d240>,
		<OpenGL._opaque.EGLSurface_pointer object at 0x7f301050d240>,
		<OpenGL._opaque.EGLContext_pointer object at 0x7f3010762c40>,
	),
	result = 0
)
